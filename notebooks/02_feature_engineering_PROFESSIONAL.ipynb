{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ff393e0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ“ Notebook Summary: Step 2 â€“ Feature Engineering\n",
    "\n",
    "This notebook generates time-aware statistical features and encodes categorical variables to prepare the dataset for machine learning modeling.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Œ Objectives\n",
    "\n",
    "- Sort data by machine and timestamp\n",
    "- Generate rolling window statistics (mean, std, min, max)\n",
    "- One-hot encode `operating_mode`\n",
    "- Output a clean, feature-rich dataset for model training\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ” Section-by-Section Overview\n",
    "\n",
    "### 1. **Import & Load**\n",
    "- Loaded pandas, numpy, matplotlib, seaborn\n",
    "- Read cleaned dataset (`agri_sensor_data_cleaned.csv`) created in Notebook 01\n",
    "\n",
    "### 2. **Sort by Time**\n",
    "- Ensured chronological order of events for each machine using `groupby` on `machine_id`\n",
    "\n",
    "### 3. **Rolling Window Features**\n",
    "- For each sensor: vibration, current, temp, torque, and RPM:\n",
    "  - Computed 30-second rolling `mean`, `std`, `min`, and `max`\n",
    "- These features help detect trends and anomalies prior to failure\n",
    "\n",
    "### 4. **Fill NaNs**\n",
    "- Filled NaNs from rolling windows with zero to avoid breaking model inputs\n",
    "\n",
    "### 5. **One-Hot Encoding**\n",
    "- Converted categorical `operating_mode` into binary columns (e.g., `operating_mode_idle`)\n",
    "- Retained all sensor + contextual signals\n",
    "\n",
    "### 6. **Drop and Save**\n",
    "- Dropped timestamp (not needed for modeling)\n",
    "- Saved the new dataset to `data/processed/agri_features.csv`\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ˆ Recommendations\n",
    "\n",
    "- Log sensor behavior over time for 1â€“2 sample machines (trend plots)\n",
    "- Investigate correlation between rolling features and failure events\n",
    "- Validate that no leakage occurs from label columns (`failure_label`, `RUL`) into feature space\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”— Link to Next Notebook\n",
    "\n",
    "This dataset feeds directly into `03_model_training.ipynb`, where models are trained to:\n",
    "- Classify failure events\n",
    "- Predict remaining useful life (RUL) via regression\n",
    "\n",
    "---\n",
    "\n",
    "âœ… **Status**: Features generated and dataset exported for ML training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9031cdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¦ Import Required Libraries\n",
    "# These libraries support data handling, visualization, and statistical feature generation.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ea00667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Cleaned dataset loaded. Shape: (32400, 11)\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“‚ Define Paths and Load Cleaned Dataset\n",
    "# We use the cleaned output from Notebook 01 to begin feature engineering.\n",
    "\n",
    "INPUT_PATH = Path(\"../data/processed/agri_sensor_data_cleaned.csv\")\n",
    "OUTPUT_PATH = Path(\"../data/processed/agri_features.csv\")\n",
    "\n",
    "df = pd.read_csv(INPUT_PATH, parse_dates=['timestamp'])\n",
    "print(\"âœ… Cleaned dataset loaded. Shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fced5051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§­ Sort Data by Machine and Timestamp\n",
    "# Ensures temporal ordering before generating rolling features.\n",
    "\n",
    "df = df.sort_values(by=['machine_id', 'timestamp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "088e584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š Generate Rolling Window Features\n",
    "# For each machine, compute rolling statistics (mean, std, min, max) over a 30-second window.\n",
    "\n",
    "window_size = 30\n",
    "sensor_cols = ['vibration_level', 'motor_current', 'motor_temp', 'torque', 'rpm']\n",
    "\n",
    "for col in sensor_cols:\n",
    "    df[f'{col}_mean'] = df.groupby('machine_id')[col].transform(lambda x: x.rolling(window_size, min_periods=1).mean())\n",
    "    df[f'{col}_std'] = df.groupby('machine_id')[col].transform(lambda x: x.rolling(window_size, min_periods=1).std())\n",
    "    df[f'{col}_min'] = df.groupby('machine_id')[col].transform(lambda x: x.rolling(window_size, min_periods=1).min())\n",
    "    df[f'{col}_max'] = df.groupby('machine_id')[col].transform(lambda x: x.rolling(window_size, min_periods=1).max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83c5e717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§¹ Fill Missing Values from Rolling Stats\n",
    "# Rolling std at start of window may result in NaNs â€” we fill them with 0.\n",
    "\n",
    "df.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bfcad99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”  One-Hot Encode Operating Mode\n",
    "# Converts the 'operating_mode' categorical column into binary columns.\n",
    "\n",
    "df = pd.get_dummies(df, columns=['operating_mode'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb265c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§¼ Drop Non-Numeric or Unused Columns\n",
    "# We drop columns not used directly for ML modeling at this stage.\n",
    "\n",
    "df_model = df.drop(columns=['timestamp'])  # machine_id retained for traceability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab5cd404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Feature-engineered dataset saved to: ..\\data\\processed\\agri_features.csv\n",
      "ğŸ“Š Final shape: (32400, 33)\n"
     ]
    }
   ],
   "source": [
    "# ğŸ’¾ Save Feature-Engineered Dataset\n",
    "# This file will be used in Notebook 03 for model training and evaluation.\n",
    "\n",
    "df_model.to_csv(OUTPUT_PATH, index=False)\n",
    "print(f\"ğŸ“ Feature-engineered dataset saved to: {OUTPUT_PATH}\")\n",
    "print(\"ğŸ“Š Final shape:\", df_model.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
